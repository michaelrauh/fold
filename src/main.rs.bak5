use fold::{
    FoldError,
    file_handler::{self, MemClaimGuard, StateConfig},
    generation_store::{GenerationStore, Config, Role},
    interner::Interner,
    metrics::Metrics,
    ortho::Ortho,
    tui::Tui,
};
use std::fs;
use std::io::IsTerminal;
use std::path::PathBuf;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::thread;
use sysinfo::ProcessesToUpdate;

const COMPLETION_CHUNK_SIZE: usize = 1_000;
const FANOUT_LOG_THRESHOLD: usize = COMPLETION_CHUNK_SIZE;

// Helper to convert Role to string
fn role_as_str(role: Role) -> &'static str {
    match role {
        Role::Leader => "leader",
        Role::Follower => "follower",
    }
}

fn main() -> Result<(), FoldError> {
    // Check for test environment variable
    let config = if let Ok(test_dir) = std::env::var("FOLD_STATE_DIR") {
        StateConfig::custom(PathBuf::from(test_dir))
    } else {
        StateConfig::default()
    };

    // Initialize: setup directories and recover abandoned files
    file_handler::initialize_with_config(&config)?;

    // Initialize metrics and TUI
    let metrics = Metrics::new();
    let log_dir = config.logs_dir();
    fs::create_dir_all(&log_dir)?;
    metrics.add_log("Log initialized".to_string());
    let should_quit = Arc::new(AtomicBool::new(false));

    let tui_enabled = std::env::var("FOLD_DISABLE_TUI").is_err() && std::io::stdout().is_terminal();

    // Spawn TUI thread with panic-forwarding so we don't leave the terminal in a broken state.
    let tui_handle = if tui_enabled {
        let metrics_clone = metrics.clone_handle();
        let should_quit_clone = Arc::clone(&should_quit);
        Some(thread::spawn(move || {
            let result = std::panic::catch_unwind(move || {
                let mut tui = Tui::new(metrics_clone, should_quit_clone);
                tui.run()
            });
            match result {
                Ok(Ok(())) => {}
                Ok(Err(e)) => panic!("TUI error: {}", e),
                Err(panic) => std::panic::resume_unwind(panic),
            }
        }))
    } else {
        metrics.add_log("TUI disabled (no TTY or FOLD_DISABLE_TUI set)".to_string());
        None
    };

    // Count initial chunks
    let total_chunks = file_handler::count_all_chunks_with_config(&config)?;
    metrics.update_global(|g| {
        g.total_chunks = total_chunks;
        g.remaining_chunks = total_chunks;
    });

    // Initialize largest archive metric from existing archives
    if let Ok(Some(largest)) = file_handler::find_largest_archive_with_config(&config) {
        metrics.update_largest_archive(|la| {
            la.filename = largest.path.clone();
            la.ortho_count = largest.ortho_count;
            la.lineage = largest.lineage;
        });

        // Load and restore the optimal ortho from the largest archive
        let optimal_ortho = file_handler::load_optimal_ortho(&largest.path)?;
        let interner = file_handler::load_interner(&largest.path)?;

        let (volume, fullness) = optimal_ortho.score();
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        metrics.update_optimal_ortho(|opt| {
            opt.volume = volume;
            opt.dims = optimal_ortho.dims().clone();
            opt.fullness = fullness;
            opt.capacity = optimal_ortho.payload().len();
            opt.payload = optimal_ortho.payload().clone();
            opt.vocab = interner.vocabulary().to_vec();
            opt.last_update_time = now;
        });
        metrics.update_global(|g| {
            g.vocab_size = interner.vocabulary().len();
            g.interner_version = interner.version();
        });
        metrics.add_log(format!(
            "Restored optimal ortho from archive: volume={}",
            volume
        ));
    }

    // Main processing loop - two modes:
    // Mode 1: Merge archives (leaders pick the largest pair; followers merge the smallest pair only when no text is free)
    // Mode 2: Process txt into result
    let main_result =
        std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| -> Result<(), FoldError> {
            let mut last_role: Option<Role> = None;
            loop {
                // Check for stale heartbeats and recover abandoned work from crashed processes
                file_handler::check_and_recover_stale_work(&config)?;
                file_handler::cleanup_stale_mem_claims(&config)?;

                let role = determine_role(&config)?;
                if last_role != Some(role) {
                    metrics.add_log(format!("Role change: {:?}", role));
                    metrics.update_global(|g| g.role = role_as_str(role).to_string());
                    last_role = Some(role);
                } else {
                    metrics.update_global(|g| g.role = role_as_str(role).to_string());
                }

                // Update the count of distinct running jobs
                let jobs_count = file_handler::count_running_jobs_with_config(&config)?;
                let remaining_chunks = file_handler::count_all_chunks_with_config(&config)?;
                metrics.update_global(|g| {
                    g.distinct_jobs_count = jobs_count;
                    g.remaining_chunks = remaining_chunks;
                    if remaining_chunks > g.total_chunks {
                        g.total_chunks = remaining_chunks;
                    }
                });

                match role {
                    Role::Leader => {
                        // Leaders prioritize merging largest archives, then process text
                        let archive_pair =
                            file_handler::get_two_largest_archives_with_config(&config)?;

                        if let Some((second_largest, largest)) = archive_pair {
                            // Mode 1: Merge archives
                            metrics.update_global(|g| g.mode = "Merging Archives".to_string());
                            metrics.clear_chart_history();
                            metrics.add_log("MODE 1: Merging archives".to_string());
                            metrics.add_log(format!("Merging: {} + {}", second_largest, largest));

                            match merge_archives(&second_largest, &largest, &config, &metrics, role)
                            {
                                Ok(()) => {}
                                Err(e) if is_concurrent_claim_error(&e) => {
                                    metrics.add_log(format!(
                                        "Lost race to claim archives ({}); retrying selection",
                                        e
                                    ));
                                    continue;
                                }
                                Err(e) => return Err(e),
                            }
                        } else {
                            // Mode 2: Process txt file
                            let txt_file = file_handler::find_txt_file_with_config(&config)?;

                            if txt_file.is_none() {
                                metrics.add_log("No more files to process".to_string());
                                metrics.add_log("Processing completed".to_string());
                                eprintln!("[fold] No txt files found, exiting");
                                break;
                            }

                            metrics.update_global(|g| g.mode = "Processing Text".to_string());
                            metrics.clear_chart_history();
                            metrics.add_log("MODE 2: Processing text file".to_string());

                            let txt_file = txt_file.unwrap();
                            match process_txt_file(txt_file.clone(), &config, &metrics, role) {
                                Ok(()) => {}
                                Err(e) if is_concurrent_claim_error(&e) => {
                                    metrics.add_log(format!(
                                        "Lost race to claim {}; retrying selection",
                                        txt_file
                                    ));
                                    continue;
                                }
                                Err(e) => return Err(e),
                            }
                        }
                    }
                    Role::Follower => {
                        // Followers prioritize ingesting new text; merge smallest archives only when none available
                        if let Some(txt_file) = file_handler::find_txt_file_with_config(&config)? {
                            metrics.update_global(|g| g.mode = "Processing Text".to_string());
                            metrics.clear_chart_history();
                            metrics.add_log("MODE 2: Processing text file".to_string());

                            match process_txt_file(txt_file.clone(), &config, &metrics, role) {
                                Ok(()) => {}
                                Err(e) if is_concurrent_claim_error(&e) => {
                                    metrics.add_log(format!(
                                        "Lost race to claim {}; retrying selection",
                                        txt_file
                                    ));
                                    continue;
                                }
                                Err(e) => return Err(e),
                            }
                        } else if let Some((smallest, second_smallest)) =
                            file_handler::get_two_smallest_archives_with_config(&config)?
                        {
                            // Mode 1 for followers: merge the two smallest archives when no text is free
                            metrics.update_global(|g| g.mode = "Merging Archives".to_string());
                            metrics.clear_chart_history();
                            metrics.add_log("MODE 1: Merging archives".to_string());
                            metrics.add_log(format!("Merging: {} + {}", smallest, second_smallest));

                            match merge_archives(
                                &smallest,
                                &second_smallest,
                                &config,
                                &metrics,
                                role,
                            ) {
                                Ok(()) => {}
                                Err(e) if is_concurrent_claim_error(&e) => {
                                    metrics.add_log(format!(
                                        "Lost race to claim archives ({}); retrying selection",
                                        e
                                    ));
                                    continue;
                                }
                                Err(e) => return Err(e),
                            }
                        } else {
                            metrics.add_log("No more files to process".to_string());
                            metrics.add_log("Processing completed".to_string());
                            break;
                        }
                    }
                }
            }
            Ok(())
        }));

    // Signal TUI to quit and wait for it
    should_quit.store(true, Ordering::Relaxed);
    let tui_result = if let Some(handle) = tui_handle {
        Some(handle.join())
    } else {
        None
    };

    cleanup_leader_lock(&config);

    match (main_result, tui_result) {
        (Ok(Ok(())), Some(Ok(()))) | (Ok(Ok(())), None) => Ok(()),
        (Ok(Ok(())), Some(Err(panic))) => std::panic::resume_unwind(panic),
        (Ok(Err(e)), _) => Err(e),
        (Err(panic), _) => std::panic::resume_unwind(panic),
    }
}

fn process_txt_file(
    file_path: String,
    config: &StateConfig,
    metrics: &Metrics,
    role: Role,
) -> Result<(), FoldError> {
    // Ingest the text file
    let ingestion = file_handler::ingest_txt_file_with_config(&file_path, config)?;
    let remaining_chunks = file_handler::count_all_chunks_with_config(config)?;
    metrics.reset_new_orthos();

    metrics.update_operation(|op| {
        op.current_file = ingestion.filename.clone();
        op.text_preview = ingestion.text_preview.clone();
        op.word_count = ingestion.word_count;
    });
    metrics.set_operation_status("Building interner".to_string());
    metrics.update_global(|g| {
        g.remaining_chunks = remaining_chunks;
        if remaining_chunks > g.total_chunks {
            g.total_chunks = remaining_chunks;
        }
        g.current_lineage = format!("\"{}\"", ingestion.filename);
    });
    metrics.add_log(format!(
        "Ingested: {} ({} remaining)",
        ingestion.filename, remaining_chunks
    ));

    // Build interner from the text
    let interner = Interner::from_text(&ingestion.text);

    metrics.update_global(|g| {
        g.interner_version = interner.version();
        g.vocab_size = interner.vocabulary().len();
    });
    metrics.add_log(format!(
        "Interner built: v{}, vocab={}",
        interner.version(),
        interner.vocabulary().len()
    ));

    // Get memory configuration based on role and current RAM state
    let Some(cfg) = Config::compute_config(role) else {
        metrics.add_log(format!(
            "Follower bailing: insufficient memory for minimum configuration"
        ));
        return Err(FoldError::Io(std::io::Error::new(
            std::io::ErrorKind::Other,
            "Follower: insufficient memory",
        )));
    };

    // Acquire memory claim for this file
    let interner_bytes = bincode::encode_to_vec(&interner, bincode::config::standard())?.len();
    let mem_claim = acquire_memory_claim_simple(role, config, metrics, interner_bytes)?;

    // Initialize GenerationStore for this file (work folder becomes gen store base)
    let store_path = PathBuf::from(ingestion.work_queue_path()).parent().unwrap().to_path_buf();
    let mut store = GenerationStore::new_with_config(store_path, 8)?;

    metrics.add_log(format!(
        "[{} init] generation_store initialized run_budget={} MB fan_in={}",
        role_as_str(role),
        cfg.run_budget_bytes / 1_048_576,
        cfg.fan_in
    ));

    // Seed with empty ortho
    let seed_ortho = Ortho::new();
    let mut best_ortho = seed_ortho.clone();
    let mut best_score = best_ortho.score();
    let mut global_score = metrics.optimal_score();
    let mut optimal_dirty = false;
    let mut total_processed = 0;

    // Push seed to work queue
    store.push_segments(vec![seed_ortho])?;

    metrics.set_operation_status("Processing orthos".to_string());

    let mut sys = sysinfo::System::new();
    let mut generation = 0u64;
    
    // Generational processing loop
    loop {
        let work_len = store.work_len();
        if work_len == 0 {
            break;
        }

        metrics.add_log(format!(
            "Generation {}: processing {} work items",
            generation, work_len
        ));
        
        let mut gen_processed = 0;
        
        // Process all work in this generation
        while let Some(ortho) = store.pop_work()? {
            gen_processed += 1;
            total_processed += 1;

            // Periodic updates
            if total_processed % 1000 == 0 {
                metrics.record_optimal_volume(best_ortho.volume());
                metrics.update_operation(|op| {
                    op.progress_current = total_processed;
                });

                if optimal_dirty {
                    let (volume, fullness) = best_score;
                    let now = std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .unwrap()
                        .as_secs();
                    metrics.update_optimal_ortho(|opt| {
                        opt.volume = volume;
                        opt.dims = best_ortho.dims().clone();
                        opt.fullness = fullness;
                        opt.capacity = best_ortho.payload().len();
                        opt.payload = best_ortho.payload().clone();
                        opt.vocab = interner.vocabulary().to_vec();
                        opt.last_update_time = now;
                    });
                    optimal_dirty = false;
                }

                // Update RAM and check follower bail-out
                sys.refresh_memory();
                let (used_bytes, total_bytes) =
                    normalize_sysinfo_mem(sys.total_memory(), sys.used_memory());
                let proc_rss_bytes = current_process_rss_bytes(&mut sys);
                let percent = if total_bytes > 0 {
                    ((used_bytes as f64 / total_bytes as f64) * 100.0).round() as usize
                } else {
                    0
                };
                let jobs_count =
                    file_handler::count_running_jobs_with_config(config).unwrap_or(0);
                metrics.update_global(|g| {
                    g.ram_bytes = used_bytes;
                    g.process_rss_bytes = proc_rss_bytes;
                    g.system_memory_percent = percent;
                    g.distinct_jobs_count = jobs_count;
                });

                // Follower bail-out on memory pressure
                if role == Role::Follower && percent >= 85 {
                    metrics.add_log(format!(
                        "Follower exiting: memory pressure (used {} MB / total {} MB)",
                        used_bytes / 1_048_576,
                        total_bytes / 1_048_576
                    ));
                    return Err(FoldError::Io(std::io::Error::new(
                        std::io::ErrorKind::Other,
                        "Follower exiting: memory pressure",
                    )));
                }
            }

            if total_processed % 50000 == 0 {
                metrics.add_log(format!("Progress: {} orthos processed", total_processed));
            }

            if total_processed % 100000 == 0 {
                print_optimal(&best_ortho, &interner);
                ingestion.touch_heartbeat()?;
                mem_claim.touch()?;
                touch_leader_lock_if_owner(config)?;
            }

            // Get requirements from ortho
            let (forbidden, required) = ortho.get_requirements();

            // Get completions from interner
            let completions = interner.intersect(&required, &forbidden);
            let total_completions = completions.len();
            if total_completions > FANOUT_LOG_THRESHOLD {
                let chunks =
                    (total_completions + COMPLETION_CHUNK_SIZE - 1) / COMPLETION_CHUNK_SIZE;
                metrics.add_log(format!(
                    "Fanout: {} completions; processing in {} chunks of {}",
                    total_completions, chunks, COMPLETION_CHUNK_SIZE
                ));
            }

            // Generate child orthos and record results
            for completion in completions {
                let children = ortho.add(completion);
                for child in children {
                    let candidate_score = child.score();
                    if candidate_score > best_score {
                        best_ortho = child.clone();
                        best_score = candidate_score;
                    }
                    if candidate_score > global_score {
                        global_score = candidate_score;
                        optimal_dirty = true;
                    }
                    
                    // Record result to landing zone
                    store.record_result(&child)?;
                }
            }
        }

        metrics.add_log(format!(
            "Generation {}: processed {} orthos",
            generation, gen_processed
        ));

        // End of generation: drain, compact, anti-join, push new work
        metrics.set_operation_status(format!("Gen {} transition", generation));
        let new_work = store.on_generation_end_ortho(&cfg)?;
        
        metrics.add_log(format!(
            "Generation {} complete: {} new work items, {} total seen",
            generation, new_work, store.seen_len_accepted()
        ));
        
        generation += 1;

        // Limit generations for safety
        if generation > 100 {
            metrics.add_log("Reached generation limit (100); stopping".to_string());
            break;
        }
    }

    metrics.add_log(format!(
        "Completed {} generations, {} total orthos",
        generation, store.seen_len_accepted()
    ));

    // Collect all results from history for archiving
    // For now, we'll collect from all buckets
    let mut all_results = Vec::new();
    for bucket in 0..8 {
        for item in store.history_iter_orthos(bucket)? {
            all_results.push(item?);
        }
    }

    if optimal_dirty {
        let (volume, fullness) = best_score;
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        metrics.update_optimal_ortho(|opt| {
            opt.volume = volume;
            opt.dims = best_ortho.dims().clone();
            opt.fullness = fullness;
            opt.capacity = best_ortho.payload().len();
            opt.payload = best_ortho.payload().clone();
            opt.vocab = interner.vocabulary().to_vec();
            opt.last_update_time = now;
        });
    }

    let total_orthos = all_results.len();
    metrics.add_log(format!("Archiving: {} orthos", total_orthos));
    metrics.increment_new_orthos(total_orthos);

    print_optimal(&best_ortho, &interner);

    eprintln!("[fold] Saving archive with {} orthos", total_orthos);
    // Save results as archive - write orthos directly to archive format
    let (archive_path, lineage) = save_archive_from_vec(
        &ingestion,
        &interner,
        all_results,
        Some(&best_ortho),
        total_orthos,
    )?;
    eprintln!("[fold] Archive saved to: {}", archive_path);

    metrics.add_log(format!("Archive saved: {}", archive_path));

    // Update largest archive
    metrics.update_largest_archive(|la| {
        if total_orthos > la.ortho_count {
            la.filename = archive_path.clone();
            la.ortho_count = total_orthos;
            la.lineage = lineage;
        }
    });

    metrics.update_global(|g| g.processed_chunks += 1);

    // Cleanup work folder
    ingestion.cleanup()?;

    Ok(())
}

fn merge_archives(
    archive_a_path: &str,
    archive_b_path: &str,
    config: &StateConfig,
    metrics: &Metrics,
    role: Role,
) -> Result<(), FoldError> {
    // Get archive ortho counts for display BEFORE ingest moves them
    let orthos_a = file_handler::load_archive_metadata(archive_a_path).unwrap_or(0);
    let orthos_b = file_handler::load_archive_metadata(archive_b_path).unwrap_or(0);

    // Ingest archives for merging
    let ingestion =
        file_handler::ingest_archives_with_config(archive_a_path, archive_b_path, config)?;

    metrics.set_operation_status("Loading interners".to_string());

    // Load both interners
    let (interner_a, interner_b) = ingestion.load_interners()?;

    // Load lineages early to display provenance tree
    let (lineage_a_early, lineage_b_early) = ingestion.load_lineages()?;
    let merged_lineage_preview = format!("({} {})", lineage_a_early, lineage_b_early);
    metrics.update_global(|g| g.current_lineage = merged_lineage_preview);

    // Determine which interner is smaller to optimize remapping
    let a_is_smaller = interner_a.vocab_size() <= interner_b.vocab_size();

    let (larger_interner, smaller_interner) = if a_is_smaller {
        (interner_b, interner_a)
    } else {
        (interner_a, interner_b)
    };

    // Create merged interner first
    let merged_interner = larger_interner.merge(&smaller_interner);

    // Now calculate impacted keys by comparing merged against originals
    // This gives us keys in MERGED vocabulary space that changed from each archive's perspective
    let impacted_larger = merged_interner.impacted_keys(&larger_interner);
    let impacted_smaller = merged_interner.impacted_keys(&smaller_interner);

    // Remap smaller's impacted keys to merged vocabulary space
    // (larger's keys are already in merged space since merge is additive)
    let vocab_map_smaller =
        build_vocab_mapping(smaller_interner.vocabulary(), merged_interner.vocabulary());
    let impacted_smaller_remapped: Vec<Vec<usize>> = impacted_smaller
        .iter()
        .map(|prefix| {
            prefix
                .iter()
                .map(|&idx| vocab_map_smaller[idx])
                .collect()
        })
        .collect();

    metrics.update_merge(|m| {
        m.current_merge = format!("merge_{}", std::process::id());
        m.archive_a_orthos = orthos_a;
        m.archive_b_orthos = orthos_b;
        m.impacted_a = if a_is_smaller {
            impacted_smaller_remapped.len()
        } else {
            impacted_larger.len()
        };
        m.impacted_b = if a_is_smaller {
            impacted_larger.len()
        } else {
            impacted_smaller_remapped.len()
        };
        m.seed_orthos_a = orthos_a;
        m.seed_orthos_b = orthos_b;
        m.text_preview_a = ingestion.text_preview_a.clone();
        m.text_preview_b = ingestion.text_preview_b.clone();
        m.word_count_a = ingestion.word_count_a;
        m.word_count_b = ingestion.word_count_b;
    });
    metrics.reset_new_orthos();

    metrics.update_global(|g| {
        g.interner_version = merged_interner.version();
        g.vocab_size = merged_interner.vocabulary().len();
    });
    metrics.add_log(format!(
        "Merged interner: v{}, vocab={} (Archive {} is smaller, remapping that side)",
        merged_interner.version(),
        merged_interner.vocabulary().len(),
        if a_is_smaller { "A" } else { "B" }
    ));

    // Get memory configuration
    let Some(cfg) = Config::compute_config(role) else {
        metrics.add_log("Follower bailing: insufficient memory for merge".to_string());
        return Err(FoldError::Io(std::io::Error::new(
            std::io::ErrorKind::Other,
            "Follower: insufficient memory",
        )));
    };

    // Acquire memory claim
    let interner_bytes =
        bincode::encode_to_vec(&merged_interner, bincode::config::standard())?.len();
    let mem_claim = acquire_memory_claim_simple(role, config, metrics, interner_bytes)?;

    // Initialize GenerationStore for merge
    let store_path = PathBuf::from(ingestion.work_queue_path()).parent().unwrap().to_path_buf();
    let mut store = GenerationStore::new_with_config(store_path, 8)?;

    metrics.add_log(format!(
        "[{} merge init] generation_store initialized run_budget={} MB fan_in={}",
        role_as_str(role),
        cfg.run_budget_bytes / 1_048_576,
        cfg.fan_in
    ));

    // Seed with empty ortho
    let seed_ortho = Ortho::new();
    let mut best_ortho = seed_ortho.clone();
    let mut best_score = best_ortho.score();
    let mut global_score = metrics.optimal_score();
    let mut optimal_dirty = false;

    store.push_segments(vec![seed_ortho])?;

    // Get results paths
    let (results_a_path, results_b_path) = ingestion.get_results_paths();

    // Set up paths and impacted keys for each archive
    // Note: larger archive orthos don't need remapping, their impacted keys are already in merged space
    // smaller archive orthos need remapping, and we use the remapped impacted keys
    let (larger_path, larger_impacted_ref, larger_name) = if a_is_smaller {
        (&results_b_path, &impacted_larger, "B")
    } else {
        (&results_a_path, &impacted_larger, "A")
    };

    let (smaller_path, smaller_impacted_ref, smaller_name) = if a_is_smaller {
        (&results_a_path, &impacted_smaller_remapped, "A")
    } else {
        (&results_b_path, &impacted_smaller_remapped, "B")
    };

    // Process larger archive (no remapping needed) - stream directly into GenerationStore
    metrics.set_operation_status(format!("Streaming Larger Archive {}", larger_name));
    
    // Create a temporary GenerationStore to read from the archive's results
    let larger_store = GenerationStore::new_with_config(PathBuf::from(larger_path), 8)?;
    
    let mut total_from_larger = 0;
    let mut impacted_from_larger = 0;
    
    // Stream all orthos from larger archive's history into our merge store
    for bucket in 0..8 {
        for result in larger_store.history_iter_orthos(bucket)? {
            let ortho = result?;
            total_from_larger += 1;
            
            // Record to landing zone (will be deduped during generation end)
            store.record_result(&ortho)?;
            
            // If impacted, also seed to work queue
            if is_ortho_impacted_fast(&ortho, larger_impacted_ref) {
                store.push_segments(vec![ortho])?;
                impacted_from_larger += 1;
            }
            
            if total_from_larger % 10000 == 0 {
                ingestion.touch_heartbeat()?;
                mem_claim.touch()?;
                metrics.update_operation(|op| op.progress_current = total_from_larger);
            }
        }
    }
    
    metrics.add_log(format!(
        "Loaded {} orthos from larger archive {} ({} impacted)",
        total_from_larger, larger_name, impacted_from_larger
    ));

    // Process smaller archive (needs remapping) - stream and remap into GenerationStore
    metrics.set_operation_status(format!("Streaming & Remapping Smaller Archive {}", smaller_name));
    
    let smaller_store = GenerationStore::new_with_config(PathBuf::from(smaller_path), 8)?;
    
    let mut total_from_smaller = 0;
    let mut impacted_from_smaller = 0;
    
    // Stream all orthos from smaller archive's history, remap, and store
    for bucket in 0..8 {
        for result in smaller_store.history_iter_orthos(bucket)? {
            let ortho = result?;
            total_from_smaller += 1;
            
            // Remap the ortho to merged vocabulary
            if let Some(remapped) = ortho.remap(&vocab_map_smaller) {
                // Record remapped ortho to landing zone
                store.record_result(&remapped)?;
                
                // If impacted, also seed to work queue
                if is_ortho_impacted_fast(&remapped, smaller_impacted_ref) {
                    store.push_segments(vec![remapped])?;
                    impacted_from_smaller += 1;
                }
            }
            
            if total_from_smaller % 10000 == 0 {
                ingestion.touch_heartbeat()?;
                mem_claim.touch()?;
                metrics.update_operation(|op| op.progress_current = total_from_smaller);
            }
        }
    }
    
    metrics.add_log(format!(
        "Loaded & remapped {} orthos from smaller archive {} ({} impacted)",
        total_from_smaller, smaller_name, impacted_from_smaller
    ));

    metrics.add_log(format!(
        "Rehydration complete: {} work items ready",
        store.work_len()
    ));

    // Now process generations just like in process_txt_file
    let mut sys = sysinfo::System::new();
    let mut generation = 0u64;
    let mut total_processed = 0;

    metrics.set_operation_status("Processing merge generations".to_string());

    loop {
        let work_len = store.work_len();
        if work_len == 0 {
            break;
        }

        metrics.add_log(format!(
            "Merge Generation {}: processing {} work items",
            generation, work_len
        ));

        let mut gen_processed = 0;

        // Process all work in this generation
        while let Some(ortho) = store.pop_work()? {
            gen_processed += 1;
            total_processed += 1;

            // Periodic updates
            if total_processed % 1000 == 0 {
                metrics.record_optimal_volume(best_ortho.volume());
                metrics.update_operation(|op| {
                    op.progress_current = total_processed;
                });

                if optimal_dirty {
                    let (volume, fullness) = best_score;
                    let now = std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .unwrap()
                        .as_secs();
                    metrics.update_optimal_ortho(|opt| {
                        opt.volume = volume;
                        opt.dims = best_ortho.dims().clone();
                        opt.fullness = fullness;
                        opt.capacity = best_ortho.payload().len();
                        opt.payload = best_ortho.payload().clone();
                        opt.vocab = merged_interner.vocabulary().to_vec();
                        opt.last_update_time = now;
                    });
                    optimal_dirty = false;
                }

                // Update RAM
                sys.refresh_memory();
                let (used_bytes, total_bytes) =
                    normalize_sysinfo_mem(sys.total_memory(), sys.used_memory());
                let proc_rss_bytes = current_process_rss_bytes(&mut sys);
                let percent = if total_bytes > 0 {
                    ((used_bytes as f64 / total_bytes as f64) * 100.0).round() as usize
                } else {
                    0
                };
                let jobs_count =
                    file_handler::count_running_jobs_with_config(config).unwrap_or(0);
                metrics.update_global(|g| {
                    g.ram_bytes = used_bytes;
                    g.process_rss_bytes = proc_rss_bytes;
                    g.system_memory_percent = percent;
                    g.distinct_jobs_count = jobs_count;
                });

                // Follower bail-out
                if role == Role::Follower && percent >= 85 {
                    metrics.add_log(format!(
                        "Follower exiting: memory pressure ({}%)",
                        percent
                    ));
                    return Err(FoldError::Io(std::io::Error::new(
                        std::io::ErrorKind::Other,
                        "Follower: memory pressure",
                    )));
                }
            }

            if total_processed % 50000 == 0 {
                metrics.add_log(format!("Merge progress: {} orthos processed", total_processed));
            }

            if total_processed % 100000 == 0 {
                print_optimal(&best_ortho, &merged_interner);
                ingestion.touch_heartbeat()?;
                mem_claim.touch()?;
                touch_leader_lock_if_owner(config)?;
            }

            // Get requirements and completions
            let (forbidden, required) = ortho.get_requirements();
            let completions = merged_interner.intersect(&required, &forbidden);

            if completions.len() > FANOUT_LOG_THRESHOLD {
                let chunks = (completions.len() + COMPLETION_CHUNK_SIZE - 1) / COMPLETION_CHUNK_SIZE;
                metrics.add_log(format!(
                    "Fanout: {} completions; {} chunks",
                    completions.len(),
                    chunks
                ));
            }

            // Generate children
            for completion in completions {
                let children = ortho.add(completion);
                for child in children {
                    let candidate_score = child.score();
                    if candidate_score > best_score {
                        best_ortho = child.clone();
                        best_score = candidate_score;
                    }
                    if candidate_score > global_score {
                        global_score = candidate_score;
                        optimal_dirty = true;
                    }
                    
                    store.record_result(&child)?;
                }
            }
        }

        metrics.add_log(format!(
            "Merge Generation {}: processed {} orthos",
            generation, gen_processed
        ));

        // End of generation
        metrics.set_operation_status(format!("Merge Gen {} transition", generation));
        let new_work = store.on_generation_end_ortho(&cfg)?;
        
        metrics.add_log(format!(
            "Merge Generation {} complete: {} new work, {} total seen",
            generation, new_work, store.seen_len_accepted()
        ));
        
        generation += 1;

        if generation > 100 {
            metrics.add_log("Reached merge generation limit (100)".to_string());
            break;
        }
    }

    metrics.add_log(format!(
        "Merge completed {} generations, {} total orthos",
        generation, store.seen_len_accepted()
    ));

    // Collect all results from history
    let mut all_results = Vec::new();
    for bucket in 0..8 {
        for item in store.history_iter_orthos(bucket)? {
            all_results.push(item?);
        }
    }

    if optimal_dirty {
        let (volume, fullness) = best_score;
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        metrics.update_optimal_ortho(|opt| {
            opt.volume = volume;
            opt.dims = best_ortho.dims().clone();
            opt.fullness = fullness;
            opt.capacity = best_ortho.payload().len();
            opt.payload = best_ortho.payload().clone();
            opt.vocab = merged_interner.vocabulary().to_vec();
            opt.last_update_time = now;
        });
    }

    let total_orthos = all_results.len();
    metrics.add_log(format!("Archiving merge: {} orthos", total_orthos));
    metrics.increment_new_orthos(total_orthos);

    print_optimal(&best_ortho, &merged_interner);

    // Save merged results as archive
    let (archive_path, lineage) = save_archive_from_vec(
        &ingestion,
        &merged_interner,
        all_results,
        Some(&best_ortho),
        total_orthos,
    )?;

    metrics.add_log(format!("Merged archive saved: {}", archive_path));

    // Update largest archive
    metrics.update_largest_archive(|la| {
        if total_orthos > la.ortho_count {
            la.filename = archive_path.clone();
            la.ortho_count = total_orthos;
            la.lineage = lineage;
        }
    });

    metrics.update_global(|g| g.processed_chunks += 1);

    // Cleanup
    ingestion.cleanup()?;

    Ok(())
}

// Helper function to build vocabulary mapping
fn build_vocab_mapping(old_vocab: &[String], new_vocab: &[String]) -> Vec<usize> {
    let mut mapping = vec![0; old_vocab.len()];
    for (old_idx, word) in old_vocab.iter().enumerate() {
        if let Some(new_idx) = new_vocab.iter().position(|w| w == word) {
            mapping[old_idx] = new_idx;
        }
    }
    mapping
}

// Helper function to check if ortho is impacted by checking if any requirement matches impacted prefixes
fn is_ortho_impacted_fast(ortho: &Ortho, impacted_prefixes: &[Vec<usize>]) -> bool {
    // Get the ortho's requirement prefixes (not the entire payload)
    let requirements = ortho.get_requirement_phrases();
    
    // Check if any requirement prefix matches any impacted prefix
    requirements.iter().any(|req| impacted_prefixes.contains(req))
}

// Helper function to save archive from Vec<Ortho> using GenerationStore format
fn save_archive_from_vec<T>(
    ingestion: &T,
    interner: &Interner,
    orthos: Vec<Ortho>,
    best_ortho: Option<&Ortho>,
    ortho_count: usize,
) -> Result<(String, String), FoldError>
where
    T: ArchiveSaver,
{
    ingestion.save_from_vec(interner, orthos, best_ortho, ortho_count)
}

// Trait for types that can save archives (TxtIngestion and ArchiveIngestion)
trait ArchiveSaver {
    fn save_from_vec(
        &self,
        interner: &Interner,
        orthos: Vec<Ortho>,
        best_ortho: Option<&Ortho>,
        ortho_count: usize,
    ) -> Result<(String, String), FoldError>;
}

impl ArchiveSaver for file_handler::TxtIngestion {
    fn save_from_vec(
        &self,
        interner: &Interner,
        orthos: Vec<Ortho>,
        best_ortho: Option<&Ortho>,
        ortho_count: usize,
    ) -> Result<(String, String), FoldError> {
        let lineage = format!("\"{}\"", self.filename);
        save_archive_vec_internal(
            interner,
            orthos,
            best_ortho,
            &lineage,
            ortho_count,
            &self.text_preview,
            self.word_count,
            self.config(),
        )
    }
}

impl ArchiveSaver for file_handler::ArchiveIngestion {
    fn save_from_vec(
        &self,
        interner: &Interner,
        orthos: Vec<Ortho>,
        best_ortho: Option<&Ortho>,
        ortho_count: usize,
    ) -> Result<(String, String), FoldError> {
        // For merge, create compound lineage
        let (lineage_a, lineage_b) = self.load_lineages()?;
        let lineage = format!("({} {})", lineage_a, lineage_b);
        
        // Use combined text preview
        let text_preview = format!("{} + {}", self.text_preview_a, self.text_preview_b);
        let word_count = self.word_count_a + self.word_count_b;
        
        save_archive_vec_internal(
            interner,
            orthos,
            best_ortho,
            &lineage,
            ortho_count,
            &text_preview,
            word_count,
            self.config(),
        )
    }
}

// Internal function to save archive from Vec<Ortho>
fn save_archive_vec_internal(
    interner: &Interner,
    orthos: Vec<Ortho>,
    best_ortho: Option<&Ortho>,
    lineage: &str,
    ortho_count: usize,
    text_preview: &str,
    word_count: usize,
    config: &StateConfig,
) -> Result<(String, String), FoldError> {
    use std::time::{SystemTime, UNIX_EPOCH};
    
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| FoldError::Io(std::io::Error::new(std::io::ErrorKind::Other, e)))?;
    
    // Create unique archive path
    let archive_name = format!(
        "archive_{}_{}",
        now.as_secs(),
        now.subsec_nanos()
    );
    let archive_path = config.input_dir().join(format!("{}=.bin", archive_name));
    
    // Create archive directory
    fs::create_dir_all(&archive_path).map_err(FoldError::Io)?;
    
    // Write orthos using GenerationStore format (history runs)
    let results_dir = archive_path.join("results");
    fs::create_dir_all(&results_dir).map_err(FoldError::Io)?;
    
    // Create a temporary GenerationStore to write orthos in the proper format
    let mut temp_store = GenerationStore::new_with_config(results_dir.clone(), 8)?;
    for ortho in orthos {
        temp_store.record_result(&ortho)?;
    }
    // Flush to ensure all orthos are written
    drop(temp_store);
    
    // Write the interner
    let interner_path = archive_path.join("interner.bin");
    let interner_bytes = bincode::encode_to_vec(interner, bincode::config::standard())?;
    fs::write(interner_path, interner_bytes).map_err(FoldError::Io)?;
    
    // Write optimal ortho if provided
    if let Some(ortho) = best_ortho {
        let optimal_bin_path = archive_path.join("optimal.bin");
        let optimal_bytes = bincode::encode_to_vec(ortho, bincode::config::standard())?;
        fs::write(optimal_bin_path, optimal_bytes).map_err(FoldError::Io)?;
    }
    
    // Write lineage
    let lineage_path = archive_path.join("lineage.txt");
    fs::write(lineage_path, lineage).map_err(FoldError::Io)?;
    
    // Write metadata
    let metadata_path = archive_path.join("metadata.txt");
    fs::write(metadata_path, ortho_count.to_string()).map_err(FoldError::Io)?;
    
    // Write text metadata
    let text_metadata_path = archive_path.join("text_metadata.txt");
    let text_metadata = format!("preview: {}\nword_count: {}", text_preview, word_count);
    fs::write(text_metadata_path, text_metadata).map_err(FoldError::Io)?;
    
    Ok((archive_path.to_string_lossy().to_string(), lineage.to_string()))
}

// Old helper functions removed (build_vocab_mapping, is_ortho_impacted_fast) - were only used by merge_archives

fn print_optimal(_ortho: &Ortho, _interner: &Interner) {
    // Optimal ortho info is now displayed in TUI metrics
}

// Simplified memory claim for GenerationStore model
fn acquire_memory_claim_simple(
    role: Role,
    config: &StateConfig,
    _metrics: &Metrics,
    _interner_bytes: usize,
) -> Result<MemClaimGuard, FoldError> {
    // GenerationStore manages its own memory via Config::compute_config
    // This just creates a placeholder claim to participate in coordination
    let granted_bytes = 100 * 1024 * 1024; // 100MB placeholder
    file_handler::create_mem_claim(config, role_as_str(role), granted_bytes, granted_bytes)
}

fn normalize_sysinfo_mem(total_raw: u64, used_raw: u64) -> (usize, usize) {
    #[cfg(target_os = "linux")]
    {
        if let Ok(meminfo) = std::fs::read_to_string("/proc/meminfo") {
            if let Some(mem_total_kib) = meminfo
                .lines()
                .find(|l| l.starts_with("MemTotal:"))
                .and_then(|line| line.split_whitespace().nth(1))
                .and_then(|v| v.parse::<u64>().ok())
            {
                let mem_total_kib_f = mem_total_kib as f64;
                // If sysinfo matches /proc/meminfo in KiB, convert to bytes.
                if within_10_pct(total_raw as f64, mem_total_kib_f) {
                    let factor = 1024usize;
                    return (
                        (used_raw as usize).saturating_mul(factor),
                        (total_raw as usize).saturating_mul(factor),
                    );
                }
                // If sysinfo already reports bytes (matches /proc/meminfo bytes), keep as-is.
                let mem_total_bytes_f = mem_total_kib_f * 1024.0;
                if within_10_pct(total_raw as f64, mem_total_bytes_f) {
                    return (used_raw as usize, total_raw as usize);
                }
            }
        }
    }
    // Fallback: assume values are in KiB, convert to bytes.
    let factor = 1024usize;
    (
        (used_raw as usize).saturating_mul(factor),
        (total_raw as usize).saturating_mul(factor),
    )
}

fn current_process_rss_bytes(sys: &mut sysinfo::System) -> usize {
    if let Ok(pid) = sysinfo::get_current_pid() {
        let _ = sys.refresh_processes(ProcessesToUpdate::Some(&[pid]), false);
        if let Some(proc) = sys.process(pid) {
            return proc.memory() as usize;
        }
    }
    0
}

// Old acquire_memory_claim kept for any remaining merge_archives code
fn determine_role(config: &StateConfig) -> Result<Role, FoldError> {
    if let Ok(force) = std::env::var("FOLD_FORCE_ROLE") {
        let force_lower = force.to_lowercase();
        if force_lower == "follower" {
            return Ok(Role::Follower);
        } else if force_lower == "leader" {
            return ensure_leader_lock(config);
        }
    }
    ensure_leader_lock(config)
}

fn ensure_leader_lock(config: &StateConfig) -> Result<Role, FoldError> {
    let lock_path = config.in_process_dir().join("leader.lock");
    fs::create_dir_all(config.in_process_dir()).map_err(FoldError::Io)?;

    let claim_leader = || -> Result<bool, FoldError> {
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| FoldError::Io(std::io::Error::new(std::io::ErrorKind::Other, e)))?
            .as_secs();
        use std::io::Write;
        use std::fs::OpenOptions;
        match OpenOptions::new()
            .write(true)
            .create_new(true)
            .open(&lock_path)
        {
            Ok(mut file) => {
                let content = format!("{}:{}", timestamp, std::process::id());
                file.write_all(content.as_bytes()).map_err(FoldError::Io)?;
                Ok(true)
            }
            Err(e) if e.kind() == std::io::ErrorKind::AlreadyExists => Ok(false),
            Err(e) => Err(FoldError::Io(e)),
        }
    };

    if lock_path.exists() {
        if file_handler::is_heartbeat_file_stale(&lock_path)? {
            let _ = fs::remove_file(&lock_path);
        } else {
            let owner_pid = fs::read_to_string(&lock_path).ok().and_then(|contents| {
                contents
                    .split(':')
                    .nth(1)
                    .and_then(|p| p.split_whitespace().next())
                    .and_then(|p| p.parse::<u32>().ok())
            });
            if owner_pid == Some(std::process::id()) {
                file_handler::touch_heartbeat_file(lock_path.to_str().unwrap())?;
                return Ok(Role::Leader);
            } else {
                return Ok(Role::Follower);
            }
        }
    }

    if claim_leader()? {
        Ok(Role::Leader)
    } else {
        Ok(Role::Follower)
    }
}

fn touch_leader_lock_if_owner(config: &StateConfig) -> Result<(), FoldError> {
    let lock_path = config.in_process_dir().join("leader.lock");

    if let Ok(contents) = fs::read_to_string(&lock_path) {
        let owner_pid = contents
            .split(':')
            .nth(1)
            .and_then(|p| p.split_whitespace().next())
            .and_then(|p| p.parse::<u32>().ok());

        if owner_pid == Some(std::process::id()) {
            file_handler::touch_heartbeat_file(lock_path.to_str().unwrap())?;
        }
    }

    Ok(())
}

fn cleanup_leader_lock(config: &StateConfig) {
    let lock_path = config.in_process_dir().join("leader.lock");
    if let Ok(contents) = fs::read_to_string(&lock_path) {
        let owner_pid = contents
            .split(':')
            .nth(1)
            .and_then(|p| p.split_whitespace().next())
            .and_then(|p| p.parse::<u32>().ok());
        if owner_pid == Some(std::process::id()) {
            let _ = fs::remove_file(lock_path);
        }
    }
}

// Treat common IO races (files already moved by another process) as recoverable.
fn is_concurrent_claim_error(err: &FoldError) -> bool {
    match err {
        FoldError::Io(io_err) => {
            matches!(
                io_err.kind(),
                std::io::ErrorKind::NotFound | std::io::ErrorKind::AlreadyExists
            ) || matches!(io_err.raw_os_error(), Some(39) | Some(66))
        }
        _ => false,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::ErrorKind;

    #[test]
    fn test_score() {
        let ortho = Ortho::new();
        let (volume, fullness) = ortho.score();
        // Empty ortho with dims [2,2] has volume (2-1)*(2-1) = 1
        assert_eq!(volume, 1);
        // All 4 slots are None
        assert_eq!(fullness, 0);
    }

    #[test]
    fn concurrent_claim_errors_are_retryable() {
        let not_found = FoldError::Io(std::io::Error::new(ErrorKind::NotFound, "missing"));
        assert!(is_concurrent_claim_error(&not_found));

        let already_exists = FoldError::Io(std::io::Error::new(ErrorKind::AlreadyExists, "exists"));
        assert!(is_concurrent_claim_error(&already_exists));

        let dir_not_empty = FoldError::Io(std::io::Error::from_raw_os_error(39));
        assert!(is_concurrent_claim_error(&dir_not_empty));

        let permission_denied =
            FoldError::Io(std::io::Error::new(ErrorKind::PermissionDenied, "denied"));
        assert!(!is_concurrent_claim_error(&permission_denied));
    }
}
