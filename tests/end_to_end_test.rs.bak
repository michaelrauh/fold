use std::fs;
use std::process::{Command, Child};
use std::thread;
use std::time::Duration;

/// End-to-end test with minimal input that completes quickly.
///
/// Creates two tiny text files "a b c d." and "a c b d." which should:
/// 1. Each file gets processed into an archive
/// 2. The two archives get merged
/// 3. Final merged archive contains an ortho with geometry:
///    a b
///    c d
#[test]
fn test_end_to_end_tiny_input() {
    // Setup: Create a temporary test environment
    let test_dir = tempfile::tempdir().unwrap();
    let test_path = test_dir.path();

    // Create state directory structure
    let state_dir = test_path.join("fold_state");
    let input_dir = state_dir.join("input");
    fs::create_dir_all(&input_dir).unwrap();

    // Create two tiny test files
    let file1 = input_dir.join("test1.txt");
    let file2 = input_dir.join("test2.txt");
    fs::write(&file1, "a b c d.").unwrap();
    fs::write(&file2, "a c b d.").unwrap();

    println!("[test] Created two input files:");
    println!("[test]   test1.txt: 'a b c d.'");
    println!("[test]   test2.txt: 'a c b d.'");

    // Build the project first
    println!("[test] Building fold...");
    let build_output = Command::new("cargo")
        .arg("build")
        .arg("--release")
        .output()
        .expect("Failed to build project");

    assert!(
        build_output.status.success(),
        "Build failed: {}",
        String::from_utf8_lossy(&build_output.stderr)
    );

    // Start fold in the background with a timeout
    println!("[test] Starting fold processor...");
    let mut fold_process: Child = Command::new("./target/release/fold")
        .env("FOLD_STATE_DIR", state_dir.to_str().unwrap())
        .env("FOLD_DISABLE_TUI", "1") // Disable TUI for testing
        .stdout(std::process::Stdio::piped())
        .stderr(std::process::Stdio::piped())
        .spawn()
        .expect("Failed to start fold");

    // Verify files exist before processing
    println!("[test] Files before processing:");
    println!("[test]   file1 exists: {}", file1.exists());
    println!("[test]   file2 exists: {}", file2.exists());

    // Give it time to process (should be very quick with tiny input)
    // We expect: 2 files -> 2 archives -> 1 merged archive
    println!("[test] Waiting for processing to complete...");
    thread::sleep(Duration::from_secs(5));

    // Kill the fold process
    fold_process.kill().ok();
    let output = fold_process.wait_with_output().ok();
    
    // Print stdout and stderr
    if let Some(output) = output {
        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        if !stdout.is_empty() {
            println!("[test] Fold stdout:");
            println!("{}", stdout);
        }
        if !stderr.is_empty() {
            println!("[test] Fold stderr:");
            println!("{}", stderr);
        }
        if stdout.is_empty() && stderr.is_empty() {
            println!("[test] WARNING: Fold produced no output!");
        }
    }

    // Check logs to see what happened
    println!("[test] Checking logs...");
    let log_dir = state_dir.join("logs");
    if log_dir.exists() {
        if let Ok(entries) = fs::read_dir(&log_dir) {
            for entry in entries.filter_map(|e| e.ok()) {
                println!("[test] Log file: {}", entry.file_name().to_string_lossy());
                if let Ok(content) = fs::read_to_string(entry.path()) {
                    println!("[test] Content:\n{}", content);
                }
            }
        }
    }

    // Verify outputs
    println!("[test] Verifying outputs...");

    // Check what directories exist in the state_dir
    println!("[test] State directory contents:");
    if let Ok(entries) = fs::read_dir(&state_dir) {
        for entry in entries.filter_map(|e| e.ok()) {
            let name = entry.file_name();
            let path = entry.path();
            println!("[test]   - {}", name.to_string_lossy());
            
            // If it's a directory, show its contents too
            if path.is_dir() && name != "mem_claims" {
                if let Ok(sub_entries) = fs::read_dir(&path) {
                    let items: Vec<_> = sub_entries.filter_map(|e| e.ok()).collect();
                    if items.is_empty() {
                        println!("[test]       (empty)");
                    } else {
                        for sub_entry in items {
                            let sub_name = sub_entry.file_name();
                            let sub_path = sub_entry.path();
                            if sub_path.is_dir() {
                                println!("[test]       - {} (dir)", sub_name.to_string_lossy());
                                // Show contents of work directories
                                if let Ok(work_entries) = fs::read_dir(&sub_path) {
                                    for work_entry in work_entries.filter_map(|e| e.ok()) {
                                        println!("[test]           - {}", work_entry.file_name().to_string_lossy());
                                    }
                                }
                            } else {
                                println!("[test]       - {}", sub_name.to_string_lossy());
                            }
                        }
                    }
                }
            }
        }
    }

    // Check input directory for archives
    let items: Vec<_> = fs::read_dir(&input_dir)
        .unwrap()
        .filter_map(|e| e.ok())
        .collect();

    println!("[test] Items in input directory: {}", items.len());
    for item in &items {
        println!("[test]   - {}", item.file_name().to_string_lossy());
    }

    // Filter for archives (directories with .bin extension)
    let archives: Vec<_> = items
        .iter()
        .filter(|e| {
            e.path().is_dir()
                && e.path()
                    .extension()
                    .map(|ext| ext == "bin")
                    .unwrap_or(false)
        })
        .collect();

    assert!(
        !archives.is_empty(),
        "Expected at least one archive, found {}",
        archives.len()
    );
    println!("[test] Found {} archive(s)", archives.len());

    // Find the largest/most recent archive (should be the merged one)
    let mut largest_archive = None;
    let mut largest_size = 0;

    for archive in &archives {
        if let Ok(metadata) = fs::read_to_string(archive.path().join("metadata.txt")) {
            if let Ok(count) = metadata.trim().parse::<usize>() {
                if count >= largest_size {
                    largest_size = count;
                    largest_archive = Some(archive);
                }
            }
        }
    }

    assert!(largest_archive.is_some(), "Could not find any valid archive");
    let archive = largest_archive.unwrap();
    let archive_path = archive.path();
    
    println!(
        "[test] Checking archive: {} (size: {} orthos)",
        archive.file_name().to_string_lossy(),
        largest_size
    );

    // Check for required files - GenerationStore format uses optimal.bin, not optimal.txt
    let interner_path = archive_path.join("interner.bin");
    let optimal_bin_path = archive_path.join("optimal.bin");
    let lineage_path = archive_path.join("lineage.txt");
    let results_path = archive_path.join("results");

    assert!(interner_path.exists(), "interner.bin not found in archive");
    assert!(optimal_bin_path.exists(), "optimal.bin not found in archive");
    assert!(lineage_path.exists(), "lineage.txt not found in archive");
    assert!(results_path.exists(), "results directory not found in archive");

    // Load and verify optimal ortho
    use fold::ortho::Ortho;
    use fold::interner::Interner;
    
    let optimal_data = fs::read(&optimal_bin_path).unwrap();
    let optimal_ortho: Ortho = bincode::decode_from_slice(&optimal_data, bincode::config::standard())
        .expect("Failed to decode optimal ortho")
        .0;
    
    let interner_data = fs::read(&interner_path).unwrap();
    let interner: Interner = bincode::decode_from_slice(&interner_data, bincode::config::standard())
        .expect("Failed to decode interner")
        .0;
    
    println!("[test] Optimal ortho dimensions: {:?}", optimal_ortho.dims());
    println!("[test] Optimal ortho volume: {}", optimal_ortho.volume());
    println!("[test] Vocabulary: {:?}", interner.vocabulary());
    
    // Use the spatial module to properly visualize the ortho like the TUI does
    use fold::spatial;
    
    println!("[test] \n=== TUI-STYLE ORTHO VISUALIZATION ===");
    
    // Get the proper coordinate mapping
    let location_to_index = spatial::get_location_to_index(optimal_ortho.dims());
    
    // For a 2D ortho, display as a grid
    if optimal_ortho.dims().len() == 2 {
        let rows = optimal_ortho.dims()[0];
        let cols = optimal_ortho.dims()[1];
        
        println!("[test] {}x{} ortho:", rows, cols);
        for row in 0..rows {
            let mut row_str = String::new();
            for col in 0..cols {
                let coords = vec![row, col];
                let cell_content = location_to_index
                    .get(&coords)
                    .and_then(|&idx| optimal_ortho.payload().get(idx))
                    .and_then(|&opt| opt)
                    .and_then(|token_id| {
                        if token_id < interner.vocab_size() {
                            Some(interner.string_for_index(token_id))
                        } else {
                            None
                        }
                    })
                    .unwrap_or("·");
                row_str.push_str(&format!("{:>4} ", cell_content));
            }
            println!("[test]   {}", row_str);
        }
    }
    println!("[test] ===================================\n");
    
    // Print the full ortho structure
    println!("[test] \n=== RAW PAYLOAD STRUCTURE ===");
    println!("[test] Ortho ID: {}", optimal_ortho.id());
    println!("[test] Dimensions: {:?}", optimal_ortho.dims());
    println!("[test] Payload ({} entries):", optimal_ortho.payload().len());
    for (i, &token_id_opt) in optimal_ortho.payload().iter().enumerate() {
        let word = if let Some(token_id) = token_id_opt {
            if token_id < interner.vocab_size() {
                interner.string_for_index(token_id)
            } else {
                "<out of bounds>"
            }
        } else {
            "<empty>"
        };
        println!("[test]   [{}] token_id={:?} word=\"{}\"", i, token_id_opt, word);
    }
    
    // Print the dimensional structure
    println!("[test] \nDimensional breakdown:");
    for (dim_idx, &dim_size) in optimal_ortho.dims().iter().enumerate() {
        println!("[test]   Dimension {}: {} values", dim_idx, dim_size);
        let start_idx = optimal_ortho.dims().iter().take(dim_idx).sum::<usize>();
        let end_idx = start_idx + dim_size;
        let tokens: Vec<String> = optimal_ortho.payload()[start_idx..end_idx]
            .iter()
            .map(|&tid_opt| {
                if let Some(tid) = tid_opt {
                    if tid < interner.vocab_size() {
                        interner.string_for_index(tid).to_string()
                    } else {
                        format!("<out of bounds: {}>", tid)
                    }
                } else {
                    "<empty>".to_string()
                }
            })
            .collect();
        println!("[test]      {:?}", tokens);
    }
    println!("[test] ================================\n");
    
    // For inputs "a b c d." and "a c b d.", we expect a 2x2 ortho:
    // Dimension 0: {a}
    // Dimension 1: {b, c}
    // This creates the structure:
    //   a b
    //   a c
    // Or some variation depending on processing order
    
    // Verify basic properties
    assert_eq!(optimal_ortho.dims().len(), 2, "Expected 2 dimensions");
    
    let vocab = interner.vocabulary();
    assert!(vocab.contains(&"a".to_string()), "Vocabulary should contain 'a'");
    assert!(vocab.contains(&"b".to_string()), "Vocabulary should contain 'b'");
    assert!(vocab.contains(&"c".to_string()), "Vocabulary should contain 'c'");
    assert!(vocab.contains(&"d".to_string()), "Vocabulary should contain 'd'");
    
    // The optimal should be 2x2 or 2x3 depending on how the merge happened
    let dims = optimal_ortho.dims();
    let total_cells = dims.iter().product::<usize>();
    assert!(
        total_cells >= 4 && total_cells <= 6,
        "Expected 4-6 cells in optimal ortho, got {}",
        total_cells
    );
    
    println!("[test] ✓ Verified optimal ortho structure");
    
    // Read and verify lineage
    let lineage_content = fs::read_to_string(&lineage_path).unwrap();
    println!("[test] Lineage: {}", lineage_content);
    
    // Lineage should reference the source files
    assert!(
        lineage_content.contains("test") || lineage_content.contains("("),
        "Expected lineage to reference test files"
    );

    println!("[test] ✓ End-to-end test completed successfully!");
}
